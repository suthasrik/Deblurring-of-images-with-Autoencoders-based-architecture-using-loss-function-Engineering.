{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1bMIrz73dP3F5KmHrmL88W8WiCA-zS8j0","authorship_tag":"ABX9TyMLd6Ay9yVaJxd7LzKbSGuN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"xWhoRLKgKJUK","executionInfo":{"status":"ok","timestamp":1690268186075,"user_tz":-330,"elapsed":3650,"user":{"displayName":"Suthasri K","userId":"02804217214680112183"}}},"outputs":[],"source":["from keras.layers import Conv2D, UpSampling2D\n","from keras.models import Sequential\n","import numpy as np\n","import tensorflow as tf\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","import random\n","import cv2\n","import os\n","from tqdm import tqdm\n","from google.colab import drive"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"-Dj40leBNnjs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["good_frames = '/content/drive/MyDrive/Autoencoders/valid_upscaled'\n","bad_frames = '/content/drive/MyDrive/Autoencoders/valid_blur'"],"metadata":{"id":"iZbYjBS1K6dG","executionInfo":{"status":"ok","timestamp":1690268189475,"user_tz":-330,"elapsed":397,"user":{"displayName":"Suthasri K","userId":"02804217214680112183"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["clean_frames = []\n","for file in tqdm(sorted(os.listdir(good_frames))):\n","  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n","    image = tf.keras.preprocessing.image.load_img(good_frames + '/' + file, target_size=(128,128))\n","    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n","    clean_frames.append(image)\n","\n","clean_frames = np.array(clean_frames)\n","blurry_frames = []\n","for file in tqdm(sorted(os.listdir(bad_frames))):\n","  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n","    image = tf.keras.preprocessing.image.load_img(bad_frames + '/' + file, target_size=(128,128))\n","    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n","    blurry_frames.append(image)\n","\n","blurry_frames = np.array(blurry_frames)\n","\n","\n","from keras.layers import Dense, Input\n","from keras.layers import Conv2D, Flatten\n","from keras.layers import Reshape, Conv2DTranspose\n","from keras.models import Model\n","from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n","from keras.utils.vis_utils import plot_model\n","from keras import backend as K\n","\n","seed = 21\n","random.seed = seed\n","np.random.seed = seed\n","\n","y_test = clean_frames;\n","X_test= blurry_frames;\n","\n","print(X_test[0].shape)\n","print(y_test[0].shape)"],"metadata":{"id":"wgOewOy6M2p8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["good1_frames = '/content/drive/MyDrive/Autoencoders/div2k_hr'\n","bad1_frames = '/content/drive/MyDrive/Autoencoders/div2k_hr_blur'\n","\n","clean1_frames = []\n","for file in tqdm(sorted(os.listdir(good1_frames))):\n","  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n","    image = tf.keras.preprocessing.image.load_img(good1_frames + '/' + file, target_size=(128,128))\n","    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n","    clean1_frames.append(image)\n","\n","clean1_frames = np.array(clean1_frames)\n","\n","blurry1_frames = []\n","for file in tqdm(sorted(os.listdir(bad1_frames))):\n","  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n","    image = tf.keras.preprocessing.image.load_img(bad1_frames + '/' + file, target_size=(128,128))\n","    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n","    blurry1_frames.append(image)\n","\n","blurry1_frames = np.array(blurry1_frames)\n","\n","y_train = clean1_frames;\n","X_train= blurry1_frames;\n","\n","\n","print(X_train[0].shape)\n","print(y_train[0].shape)\n"],"metadata":{"id":"X69yZzGoM9Z1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r = random.randint(0, len(clean_frames)-1)\n","print(r)\n","fig = plt.figure()\n","fig.subplots_adjust(hspace=0.1, wspace=0.2)\n","ax = fig.add_subplot(1, 2, 1)\n","ax.imshow(clean_frames[r])\n","ax = fig.add_subplot(1, 2, 2)\n","ax.imshow(blurry_frames[r])\n","\n","z= random.randint(0, len(clean1_frames)-1)\n","print(z)\n","fig = plt.figure()\n","fig.subplots_adjust(hspace=0.1, wspace=0.2)\n","ax = fig.add_subplot(1, 2, 1)\n","ax.imshow(y_train[z])\n","ax = fig.add_subplot(1, 2, 2)\n","ax.imshow(blurry1_frames[z])"],"metadata":{"id":"saXbMRTnNOqX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, UpSampling2D, PReLU\n","\n","model = Sequential()\n","model.add(Conv2D(64, (3, 3), padding='same', strides=2, input_shape=(128, 128, 3)))\n","model.add(PReLU())\n","model.add(Conv2D(128, (3, 3), padding='same'))\n","model.add(PReLU())\n","model.add(Conv2D(128, (3, 3), padding='same', strides=2))\n","model.add(PReLU())\n","model.add(Conv2D(256, (3, 3), padding='same'))\n","model.add(PReLU())\n","model.add(Conv2D(256, (3, 3), padding='same', strides=2))\n","model.add(PReLU())\n","model.add(Conv2D(512, (3, 3), padding='same'))\n","model.add(PReLU())\n","model.add(Conv2D(512, (3, 3), padding='same'))\n","model.add(PReLU())\n","model.add(Conv2D(256, (3, 3), padding='same'))\n","model.add(PReLU())\n","\n","model.add(Conv2D(128, (3, 3), padding='same'))\n","model.add(PReLU())\n","model.add(UpSampling2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(PReLU())\n","model.add(UpSampling2D((2, 2)))\n","model.add(Conv2D(32, (3, 3), padding='same'))\n","model.add(PReLU())\n","model.add(Conv2D(16, (3, 3), padding='same'))\n","model.add(PReLU())\n","model.add(Conv2D(2, (3, 3), padding='same', activation='tanh'))\n","model.add(Conv2D(filters=3, kernel_size=(1, 1)))\n","model.add(PReLU())\n","model.add(UpSampling2D((2, 2)))\n","\n","model.summary()\n","\n","import tensorflow.keras.backend as K\n","\n","def mse_loss(y_true, y_pred):\n","    return K.mean(K.square(y_true - y_pred))\n","\n","\n","def mean_gradient_error(y_true, y_pred):\n","    # Compute gradients of y_true and y_pred\n","    dy_true_dx = K.abs(y_true[:, :, :-1, :] - y_true[:, :, 1:, :])\n","    dy_pred_dx = K.abs(y_pred[:, :, :-1, :] - y_pred[:, :, 1:, :])\n","    dx_true_dy = K.abs(y_true[:, :-1, :, :] - y_true[:, 1:, :, :])\n","    dx_pred_dy = K.abs(y_pred[:, :-1, :, :] - y_pred[:, 1:, :, :])\n","\n","    # Compute mean gradient error\n","    mge_loss = K.mean(K.abs(dy_true_dx - dy_pred_dx) + K.abs(dx_true_dy - dx_pred_dy))\n","\n","    return mge_loss\n","\n","def psnr(y_true, y_pred):\n","    max_pixel = 1.0\n","    mse = tf.keras.losses.mean_squared_error(y_true, y_pred)\n","    psnr_val = 10.0 * tf.math.log((max_pixel ** 2) / mse) / tf.math.log(10.0)\n","    return tf.where(tf.math.is_nan(psnr_val), tf.zeros_like(psnr_val), psnr_val)\n","\n","def mse(y_true, y_pred):\n","    mse_val = tf.keras.losses.mean_squared_error(y_true, y_pred)\n","    return tf.where(tf.math.is_nan(mse_val), tf.zeros_like(mse_val), mse_val)\n","\n","def pearson_similarity(y_true, y_pred):\n","    true_flat = tf.keras.backend.flatten(y_true)\n","    pred_flat = tf.keras.backend.flatten(y_pred)\n","\n","    true_mean = tf.reduce_mean(true_flat)\n","    pred_mean = tf.reduce_mean(pred_flat)\n","\n","    true_std = tf.keras.backend.std(true_flat)\n","    pred_std = tf.keras.backend.std(pred_flat)\n","\n","    num = tf.reduce_mean((true_flat - true_mean) * (pred_flat - pred_mean))\n","    denom = true_std * pred_std\n","\n","    similarity = num / denom\n","    return tf.where(tf.math.is_nan(similarity), tf.zeros_like(similarity), similarity)\n","\n","from tensorflow.keras.losses import Loss\n","\n","class CosineDissimilarityLoss(Loss):\n","    def __init__(self):\n","        super(CosineDissimilarityLoss, self).__init__()\n","\n","    def call(self, y_true, y_pred):\n","        # Normalize the vectors\n","        y_true = tf.math.l2_normalize(y_true, axis=-1)\n","        y_pred = tf.math.l2_normalize(y_pred, axis=-1)\n","\n","        # Calculate the cosine similarity\n","        cosine_similarity = tf.reduce_sum(y_true * y_pred, axis=-1)\n","\n","        # Calculate the cosine dissimilarity loss\n","        cosine_dissimilarity_loss = 1 - cosine_similarity\n","\n","        return cosine_dissimilarity_loss\n","\n","loss_fn = CosineDissimilarityLoss()\n","\n","def combined_loss(y_true, y_pred):\n","    # Calculate Mean Squared Error (MSE) loss\n","    mse_loss = tf.keras.losses.MSE(y_true, y_pred)\n","\n","    # Calculate Mean Gradient Error (MGE) loss\n","    gradients_true = tf.image.image_gradients(y_true)\n","    gradients_pred = tf.image.image_gradients(y_pred)\n","    mge_loss = tf.keras.losses.MSE(gradients_true, gradients_pred)\n","\n","    # Calculate Cosine Distance loss\n","    cosine_loss = tf.keras.losses.cosine_similarity(y_true, y_pred)\n","    cosine_distance = 1 - cosine_loss\n","\n","    # Apply weights to the losses\n","    weighted_mse_loss = mse_loss * 1.0                 # Weight for MSE loss is 1.0\n","    weighted_mge_loss = mge_loss * 0.2                 # Weight for MGE loss is 0.1\n","    weighted_cosine_distance = cosine_distance * 1.0   # Weight for cosine distance loss is 1.0\n","\n","    # Calculate combined loss\n","    combined_loss = weighted_mse_loss + weighted_mge_loss + weighted_cosine_distance\n","    return combined_loss\n","\n","model.compile(loss=combined_loss, optimizer='adam',metrics=[psnr,mse,pearson_similarity])\n","\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               verbose=1,\n","                               min_lr=0.5e-6)\n","\n","callbacks = [lr_reducer]\n","\n","\n","history = model.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=5000,\n","                      batch_size=32, callbacks=[lr_reducer])\n","\n"],"metadata":{"id":"suuVCCn5KdIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","\n","print(\"\\n       Input                        Ground Truth                  Predicted Value\")\n","for i in range(3):\n","\n","    r = random.randint(0, len(clean_frames)-1)\n","\n","    x, y = blurry_frames[r],clean_frames[r]\n","    x_inp = x.reshape(1,128,128,3)\n","    result = model.predict(x_inp)\n","    result = result.reshape(128,128,3)\n","\n","    fig = plt.figure(figsize=(12,10))\n","    fig.subplots_adjust(hspace=0.1, wspace=0.2)\n","\n","    ax = fig.add_subplot(1, 3, 1)\n","    ax.imshow(x)\n","\n","    ax = fig.add_subplot(1, 3, 2)\n","    ax.imshow(y)\n","\n","    ax = fig.add_subplot(1, 3, 3)\n","    plt.imshow(result)\n","\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Plot training history\n","history_df = pd.DataFrame(history.history)\n","plt.figure(figsize=(10, 7))\n","history_df.plot()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training History')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"zPrUwm14N61S"},"execution_count":null,"outputs":[]}]}